{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"#113D68\" size=6>Deep Learning con Python y Keras</font></h1>\n",
    "\n",
    "<h1><font color=\"#113D68\" size=5>Multilayer Perceptron</font></h1>\n",
    "\n",
    "<h1><font color=\"#113D68\" size=4>Evaluar el rendimiento</font></h1>\n",
    "\n",
    "<h1><font color=\"#113D68\" size=4>Evaluate the performance</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#113D68\" size=3>Ayelén Stefanía Andrade</font><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "* [0. Contexto](#section0)\n",
    "* [1. Evaluar empíricamente las configuraciones de red](#section1)\n",
    "* [2. División de datos](#section2)\n",
    "    * [2.1. Verificación automática](#section2.1)\n",
    "    * [2.2. Verificación manual](#section2.2)\n",
    "* [3. Validación cruzada](#section3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section0\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 0. Contexto</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta lección, descubrirá algunas formas que puede utilizar para evaluar el rendimiento del modelo. Después de completar esta lección, sabrá:\n",
    "* Cómo evaluar un modelo utilizando un conjunto de datos de verificación automática.\n",
    "* Cómo evaluar un modelo utilizando un conjunto de datos de verificación manual.\n",
    "* Cómo evaluar un modelo mediante la validación cruzada de k-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Eliminar warning\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\" size=6>1. Evaluar empíricamente las configuraciones de red</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de evaluar modelos tenemos que tener en cuenta decisiones de nivel inferior como la elección de la función de pérdida, funciones de activación, procedimiento de optimización y número de épocas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\" size=6>2. División de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es común utilizar una simple separación de datos en conjuntos de datos de entrenamiento y validación. Keras proporciona dos formas convenientes de evaluar sus algoritmos de Deep Learning de esta manera:\n",
    "1. Utilice un conjunto de datos de verificación automática.\n",
    "2. Utilice un conjunto de datos de verificación manual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2.1\"></a>\n",
    "# <font color=\"#004D7F\" size=5>2.1. Verificación automática</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras puede separar una parte de sus datos de entrenamiento/validación y evaluar el rendimiento del modelo en cada época. Puede hacer esto configurando el argumento `validation_split` en la función `fit()` en un porcentaje del tamaño de su conjunto de datos de entrenamiento. \n",
    "\n",
    "Veamos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "52/52 [==============================] - 1s 7ms/step - loss: 11.5880 - accuracy: 0.4864 - val_loss: 5.9569 - val_accuracy: 0.5079\n",
      "Epoch 2/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 5.1923 - accuracy: 0.5214 - val_loss: 3.7330 - val_accuracy: 0.5157\n",
      "Epoch 3/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 3.1683 - accuracy: 0.5311 - val_loss: 2.7473 - val_accuracy: 0.5079\n",
      "Epoch 4/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.5947 - accuracy: 0.5486 - val_loss: 2.7171 - val_accuracy: 0.4764\n",
      "Epoch 5/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 2.2900 - accuracy: 0.5759 - val_loss: 2.1543 - val_accuracy: 0.5551\n",
      "Epoch 6/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 2.0410 - accuracy: 0.5895 - val_loss: 2.2820 - val_accuracy: 0.5079\n",
      "Epoch 7/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.7720 - accuracy: 0.5817 - val_loss: 1.7516 - val_accuracy: 0.5709\n",
      "Epoch 8/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.6838 - accuracy: 0.5934 - val_loss: 2.1994 - val_accuracy: 0.5827\n",
      "Epoch 9/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.6024 - accuracy: 0.6051 - val_loss: 1.7287 - val_accuracy: 0.5433\n",
      "Epoch 10/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.4938 - accuracy: 0.5778 - val_loss: 1.7333 - val_accuracy: 0.5669\n",
      "Epoch 11/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.3955 - accuracy: 0.5856 - val_loss: 1.6937 - val_accuracy: 0.5630\n",
      "Epoch 12/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.4238 - accuracy: 0.6031 - val_loss: 1.5507 - val_accuracy: 0.5472\n",
      "Epoch 13/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.3459 - accuracy: 0.5895 - val_loss: 1.5553 - val_accuracy: 0.5354\n",
      "Epoch 14/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.3080 - accuracy: 0.5623 - val_loss: 1.2957 - val_accuracy: 0.5669\n",
      "Epoch 15/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.3090 - accuracy: 0.6109 - val_loss: 1.3021 - val_accuracy: 0.5591\n",
      "Epoch 16/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.2551 - accuracy: 0.5817 - val_loss: 1.3047 - val_accuracy: 0.5787\n",
      "Epoch 17/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.3003 - accuracy: 0.6167 - val_loss: 1.6490 - val_accuracy: 0.5000\n",
      "Epoch 18/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.2083 - accuracy: 0.6089 - val_loss: 1.4354 - val_accuracy: 0.5630\n",
      "Epoch 19/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.2048 - accuracy: 0.6226 - val_loss: 1.3150 - val_accuracy: 0.5551\n",
      "Epoch 20/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.2380 - accuracy: 0.6245 - val_loss: 1.1783 - val_accuracy: 0.5709\n",
      "Epoch 21/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.1608 - accuracy: 0.6226 - val_loss: 1.1298 - val_accuracy: 0.5748\n",
      "Epoch 22/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0500 - accuracy: 0.6148 - val_loss: 1.2786 - val_accuracy: 0.5315\n",
      "Epoch 23/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0689 - accuracy: 0.6167 - val_loss: 1.2280 - val_accuracy: 0.5669\n",
      "Epoch 24/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.0610 - accuracy: 0.6245 - val_loss: 1.2163 - val_accuracy: 0.5472\n",
      "Epoch 25/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.0808 - accuracy: 0.6109 - val_loss: 1.1597 - val_accuracy: 0.5748\n",
      "Epoch 26/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.0970 - accuracy: 0.5973 - val_loss: 1.0797 - val_accuracy: 0.5630\n",
      "Epoch 27/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.0417 - accuracy: 0.6148 - val_loss: 1.1057 - val_accuracy: 0.5591\n",
      "Epoch 28/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.0766 - accuracy: 0.6051 - val_loss: 1.1550 - val_accuracy: 0.5512\n",
      "Epoch 29/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.9833 - accuracy: 0.5895 - val_loss: 1.2662 - val_accuracy: 0.5709\n",
      "Epoch 30/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9926 - accuracy: 0.6401 - val_loss: 1.2234 - val_accuracy: 0.5630\n",
      "Epoch 31/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9396 - accuracy: 0.6323 - val_loss: 1.2974 - val_accuracy: 0.6142\n",
      "Epoch 32/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.9429 - accuracy: 0.6265 - val_loss: 1.0332 - val_accuracy: 0.5866\n",
      "Epoch 33/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9243 - accuracy: 0.6070 - val_loss: 1.0817 - val_accuracy: 0.5591\n",
      "Epoch 34/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9143 - accuracy: 0.6187 - val_loss: 1.0436 - val_accuracy: 0.5472\n",
      "Epoch 35/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8911 - accuracy: 0.6304 - val_loss: 0.9781 - val_accuracy: 0.5866\n",
      "Epoch 36/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8724 - accuracy: 0.6440 - val_loss: 1.0317 - val_accuracy: 0.5354\n",
      "Epoch 37/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9455 - accuracy: 0.6245 - val_loss: 0.9481 - val_accuracy: 0.5630\n",
      "Epoch 38/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9645 - accuracy: 0.6012 - val_loss: 1.1365 - val_accuracy: 0.5591\n",
      "Epoch 39/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8505 - accuracy: 0.6109 - val_loss: 1.0737 - val_accuracy: 0.6260\n",
      "Epoch 40/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8810 - accuracy: 0.6304 - val_loss: 0.9136 - val_accuracy: 0.5906\n",
      "Epoch 41/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8416 - accuracy: 0.6381 - val_loss: 0.9176 - val_accuracy: 0.6102\n",
      "Epoch 42/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7801 - accuracy: 0.6381 - val_loss: 0.9829 - val_accuracy: 0.5433\n",
      "Epoch 43/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9004 - accuracy: 0.6187 - val_loss: 1.2341 - val_accuracy: 0.4803\n",
      "Epoch 44/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9809 - accuracy: 0.6167 - val_loss: 1.0340 - val_accuracy: 0.5748\n",
      "Epoch 45/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7913 - accuracy: 0.6265 - val_loss: 0.9295 - val_accuracy: 0.5906\n",
      "Epoch 46/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8007 - accuracy: 0.6556 - val_loss: 0.9326 - val_accuracy: 0.5669\n",
      "Epoch 47/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.8529 - accuracy: 0.6323 - val_loss: 1.0167 - val_accuracy: 0.5512\n",
      "Epoch 48/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7698 - accuracy: 0.6440 - val_loss: 0.8638 - val_accuracy: 0.5906\n",
      "Epoch 49/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7144 - accuracy: 0.6751 - val_loss: 0.9853 - val_accuracy: 0.5394\n",
      "Epoch 50/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.6304 - val_loss: 0.8571 - val_accuracy: 0.6142\n",
      "Epoch 51/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7523 - accuracy: 0.6420 - val_loss: 0.8305 - val_accuracy: 0.6299\n",
      "Epoch 52/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7787 - accuracy: 0.6401 - val_loss: 0.9395 - val_accuracy: 0.6024\n",
      "Epoch 53/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6994 - accuracy: 0.6518 - val_loss: 0.9538 - val_accuracy: 0.6457\n",
      "Epoch 54/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7519 - accuracy: 0.6342 - val_loss: 0.8997 - val_accuracy: 0.5748\n",
      "Epoch 55/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9165 - accuracy: 0.6148 - val_loss: 1.3905 - val_accuracy: 0.6457\n",
      "Epoch 56/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7638 - accuracy: 0.6595 - val_loss: 0.8115 - val_accuracy: 0.6063\n",
      "Epoch 57/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7305 - accuracy: 0.6206 - val_loss: 0.8611 - val_accuracy: 0.5945\n",
      "Epoch 58/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6859 - accuracy: 0.6712 - val_loss: 0.9444 - val_accuracy: 0.5394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7132 - accuracy: 0.6770 - val_loss: 0.8086 - val_accuracy: 0.6181\n",
      "Epoch 60/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.6556 - val_loss: 0.8581 - val_accuracy: 0.6102\n",
      "Epoch 61/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.6809 - val_loss: 0.7985 - val_accuracy: 0.6299\n",
      "Epoch 62/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8466 - accuracy: 0.6459 - val_loss: 0.7920 - val_accuracy: 0.6142\n",
      "Epoch 63/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.6479 - val_loss: 0.8367 - val_accuracy: 0.5748\n",
      "Epoch 64/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.6634 - val_loss: 0.7723 - val_accuracy: 0.6024\n",
      "Epoch 65/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.6265 - val_loss: 0.8666 - val_accuracy: 0.6575\n",
      "Epoch 66/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.6595 - val_loss: 0.8173 - val_accuracy: 0.5906\n",
      "Epoch 67/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.6440 - val_loss: 0.9004 - val_accuracy: 0.5827\n",
      "Epoch 68/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7191 - accuracy: 0.6615 - val_loss: 0.7727 - val_accuracy: 0.6220\n",
      "Epoch 69/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.6634 - val_loss: 0.7815 - val_accuracy: 0.6260\n",
      "Epoch 70/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6913 - accuracy: 0.6498 - val_loss: 0.8505 - val_accuracy: 0.5591\n",
      "Epoch 71/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7013 - accuracy: 0.6654 - val_loss: 0.9689 - val_accuracy: 0.5748\n",
      "Epoch 72/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7250 - accuracy: 0.6498 - val_loss: 0.7757 - val_accuracy: 0.6339\n",
      "Epoch 73/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7037 - accuracy: 0.6634 - val_loss: 0.9690 - val_accuracy: 0.5276\n",
      "Epoch 74/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7669 - accuracy: 0.6965 - val_loss: 0.9197 - val_accuracy: 0.5787\n",
      "Epoch 75/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6950 - accuracy: 0.6518 - val_loss: 0.8422 - val_accuracy: 0.6417\n",
      "Epoch 76/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6859 - accuracy: 0.6848 - val_loss: 0.8080 - val_accuracy: 0.5827\n",
      "Epoch 77/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.6479 - val_loss: 0.7429 - val_accuracy: 0.6575\n",
      "Epoch 78/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7027 - accuracy: 0.6440 - val_loss: 0.9642 - val_accuracy: 0.6535\n",
      "Epoch 79/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7357 - accuracy: 0.6498 - val_loss: 0.9036 - val_accuracy: 0.5866\n",
      "Epoch 80/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.6868 - val_loss: 0.7545 - val_accuracy: 0.6772\n",
      "Epoch 81/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7038 - accuracy: 0.6498 - val_loss: 0.8365 - val_accuracy: 0.5945\n",
      "Epoch 82/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7013 - accuracy: 0.6829 - val_loss: 0.7940 - val_accuracy: 0.6299\n",
      "Epoch 83/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7895 - accuracy: 0.6440 - val_loss: 0.7656 - val_accuracy: 0.6732\n",
      "Epoch 84/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.6693 - val_loss: 0.7802 - val_accuracy: 0.6457\n",
      "Epoch 85/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6848 - val_loss: 0.8392 - val_accuracy: 0.5827\n",
      "Epoch 86/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.6770 - val_loss: 0.7629 - val_accuracy: 0.6811\n",
      "Epoch 87/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.6654 - val_loss: 0.8802 - val_accuracy: 0.6378\n",
      "Epoch 88/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.6440 - val_loss: 0.8465 - val_accuracy: 0.6339\n",
      "Epoch 89/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.6829 - val_loss: 0.7235 - val_accuracy: 0.6654\n",
      "Epoch 90/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.6926 - val_loss: 0.9134 - val_accuracy: 0.6181\n",
      "Epoch 91/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7012 - accuracy: 0.6420 - val_loss: 0.7058 - val_accuracy: 0.6811\n",
      "Epoch 92/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.6770 - val_loss: 0.7220 - val_accuracy: 0.6575\n",
      "Epoch 93/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7156 - accuracy: 0.6595 - val_loss: 0.9393 - val_accuracy: 0.5039\n",
      "Epoch 94/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.6887 - val_loss: 0.7073 - val_accuracy: 0.6732\n",
      "Epoch 95/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.6984 - val_loss: 0.7624 - val_accuracy: 0.6260\n",
      "Epoch 96/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.6770 - val_loss: 0.7653 - val_accuracy: 0.6457\n",
      "Epoch 97/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.6654 - val_loss: 0.7086 - val_accuracy: 0.6654\n",
      "Epoch 98/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.6946 - val_loss: 0.7076 - val_accuracy: 0.7008\n",
      "Epoch 99/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.7101 - val_loss: 0.7313 - val_accuracy: 0.6417\n",
      "Epoch 100/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6312 - accuracy: 0.6946 - val_loss: 0.7240 - val_accuracy: 0.6575\n",
      "Epoch 101/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6770 - val_loss: 0.7229 - val_accuracy: 0.6181\n",
      "Epoch 102/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.6848 - val_loss: 0.7029 - val_accuracy: 0.6654\n",
      "Epoch 103/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.6946 - val_loss: 0.8244 - val_accuracy: 0.6102\n",
      "Epoch 104/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.6848 - val_loss: 0.7197 - val_accuracy: 0.6220\n",
      "Epoch 105/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.6809 - val_loss: 0.7421 - val_accuracy: 0.6732\n",
      "Epoch 106/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.7043 - val_loss: 0.7375 - val_accuracy: 0.6220\n",
      "Epoch 107/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.7140 - val_loss: 0.6860 - val_accuracy: 0.6890\n",
      "Epoch 108/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7276 - val_loss: 0.7118 - val_accuracy: 0.6732\n",
      "Epoch 109/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.6946 - val_loss: 0.7129 - val_accuracy: 0.6772\n",
      "Epoch 110/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.6848 - val_loss: 0.7094 - val_accuracy: 0.6693\n",
      "Epoch 111/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.7023 - val_loss: 0.6637 - val_accuracy: 0.6969\n",
      "Epoch 112/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7140 - val_loss: 0.6992 - val_accuracy: 0.6772\n",
      "Epoch 113/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.7023 - val_loss: 0.6719 - val_accuracy: 0.6969\n",
      "Epoch 114/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.6965 - val_loss: 0.7814 - val_accuracy: 0.6575\n",
      "Epoch 115/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.6829 - val_loss: 0.7769 - val_accuracy: 0.6417\n",
      "Epoch 116/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6712 - val_loss: 0.9045 - val_accuracy: 0.6339\n",
      "Epoch 117/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.6751 - val_loss: 0.7085 - val_accuracy: 0.6732\n",
      "Epoch 118/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7198 - val_loss: 0.6975 - val_accuracy: 0.7165\n",
      "Epoch 119/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.6829 - val_loss: 0.7508 - val_accuracy: 0.6142\n",
      "Epoch 120/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7140 - val_loss: 0.7578 - val_accuracy: 0.6811\n",
      "Epoch 121/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.6965 - val_loss: 0.9999 - val_accuracy: 0.6496\n",
      "Epoch 122/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7254 - accuracy: 0.6770 - val_loss: 0.7261 - val_accuracy: 0.6457\n",
      "Epoch 123/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7140 - val_loss: 0.7135 - val_accuracy: 0.5984\n",
      "Epoch 124/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7148 - accuracy: 0.7179 - val_loss: 0.8712 - val_accuracy: 0.7244\n",
      "Epoch 125/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.7276 - val_loss: 0.7034 - val_accuracy: 0.6378\n",
      "Epoch 126/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.7101 - val_loss: 0.6959 - val_accuracy: 0.6654\n",
      "Epoch 127/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.6868 - val_loss: 0.6865 - val_accuracy: 0.6811\n",
      "Epoch 128/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7121 - val_loss: 0.7145 - val_accuracy: 0.6575\n",
      "Epoch 129/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.7082 - val_loss: 0.6817 - val_accuracy: 0.7008\n",
      "Epoch 130/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.6848 - val_loss: 0.7959 - val_accuracy: 0.6496\n",
      "Epoch 131/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7198 - val_loss: 0.6705 - val_accuracy: 0.6890\n",
      "Epoch 132/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7043 - val_loss: 0.7554 - val_accuracy: 0.6575\n",
      "Epoch 133/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.6790 - val_loss: 0.9633 - val_accuracy: 0.6181\n",
      "Epoch 134/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.7393 - val_loss: 0.7363 - val_accuracy: 0.6142\n",
      "Epoch 135/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6848 - val_loss: 0.6965 - val_accuracy: 0.6969\n",
      "Epoch 136/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7374 - val_loss: 0.7229 - val_accuracy: 0.6772\n",
      "Epoch 137/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.6965 - val_loss: 0.7557 - val_accuracy: 0.6457\n",
      "Epoch 138/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7315 - val_loss: 0.7269 - val_accuracy: 0.6220\n",
      "Epoch 139/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.6984 - val_loss: 0.7069 - val_accuracy: 0.6496\n",
      "Epoch 140/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7335 - val_loss: 0.7523 - val_accuracy: 0.6654\n",
      "Epoch 141/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.7198 - val_loss: 0.8582 - val_accuracy: 0.6575\n",
      "Epoch 142/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.6907 - val_loss: 0.6814 - val_accuracy: 0.7165\n",
      "Epoch 143/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7160 - val_loss: 0.7177 - val_accuracy: 0.6496\n",
      "Epoch 144/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7335 - val_loss: 0.6967 - val_accuracy: 0.6575\n",
      "Epoch 145/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.7179 - val_loss: 0.7469 - val_accuracy: 0.6890\n",
      "Epoch 146/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.6556 - val_loss: 0.6669 - val_accuracy: 0.6929\n",
      "Epoch 147/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7237 - val_loss: 0.6713 - val_accuracy: 0.6772\n",
      "Epoch 148/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.7043 - val_loss: 0.6719 - val_accuracy: 0.7205\n",
      "Epoch 149/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7257 - val_loss: 0.8008 - val_accuracy: 0.6496\n",
      "Epoch 150/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7123 - accuracy: 0.6712 - val_loss: 1.0434 - val_accuracy: 0.5079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a107aa760>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP with automatic validation set\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "# load pima indians dataset\n",
    "dataset = np.loadtxt('Datasets/pima-indians-diabetes.csv', delimiter =',')\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "x = dataset[:, 0:8]\n",
    "y = dataset[:, 8]\n",
    "y\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense( 12, input_dim = 8, activation = 'relu'))\n",
    "model.add(Dense( 8, activation = 'relu'))\n",
    "model.add(Dense( 1, activation = 'sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(x,y, validation_split = 0.33, epochs = 150, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2.2\"></a>\n",
    "# <font color=\"#004D7F\" size=5>2.2. Verificación manual</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras también le permite especificar manualmente el conjunto de datos que se utilizará para la validación durante el entrenamiento. En este ejemplo usamos la práctica función `train_test_split()` de Scikit-learn usando un 67%/33%. \n",
    "\n",
    "El conjunto de datos de validación se puede especificar a la función `fit()` mediante el argumento `validation_data`. Toma una tupla de los conjuntos de datos de entrada (X) y salida (y).\n",
    "\n",
    "Veamos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 31.8813 - accuracy: 0.3677 - val_loss: 14.9033 - val_accuracy: 0.4252\n",
      "Epoch 2/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 9.4616 - accuracy: 0.4805 - val_loss: 6.7593 - val_accuracy: 0.4764\n",
      "Epoch 3/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 3.8990 - accuracy: 0.5311 - val_loss: 2.4824 - val_accuracy: 0.5591\n",
      "Epoch 4/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.9619 - accuracy: 0.5934 - val_loss: 1.6707 - val_accuracy: 0.6299\n",
      "Epoch 5/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.6060 - accuracy: 0.5895 - val_loss: 1.4038 - val_accuracy: 0.6102\n",
      "Epoch 6/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.3484 - accuracy: 0.5953 - val_loss: 1.4887 - val_accuracy: 0.6457\n",
      "Epoch 7/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.1740 - accuracy: 0.6304 - val_loss: 1.0917 - val_accuracy: 0.6260\n",
      "Epoch 8/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0926 - accuracy: 0.6051 - val_loss: 1.0811 - val_accuracy: 0.6417\n",
      "Epoch 9/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0862 - accuracy: 0.6206 - val_loss: 0.9368 - val_accuracy: 0.6378\n",
      "Epoch 10/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0265 - accuracy: 0.6089 - val_loss: 0.8882 - val_accuracy: 0.6614\n",
      "Epoch 11/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9816 - accuracy: 0.6226 - val_loss: 0.9567 - val_accuracy: 0.6339\n",
      "Epoch 12/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9070 - accuracy: 0.6323 - val_loss: 0.9759 - val_accuracy: 0.6693\n",
      "Epoch 13/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9931 - accuracy: 0.6284 - val_loss: 1.0357 - val_accuracy: 0.5433\n",
      "Epoch 14/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8895 - accuracy: 0.6187 - val_loss: 0.8646 - val_accuracy: 0.6417\n",
      "Epoch 15/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9481 - accuracy: 0.6070 - val_loss: 0.7547 - val_accuracy: 0.6929\n",
      "Epoch 16/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8179 - accuracy: 0.6440 - val_loss: 0.7464 - val_accuracy: 0.6969\n",
      "Epoch 17/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8107 - accuracy: 0.6479 - val_loss: 0.7273 - val_accuracy: 0.6929\n",
      "Epoch 18/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8675 - accuracy: 0.5856 - val_loss: 0.7356 - val_accuracy: 0.6929\n",
      "Epoch 19/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8043 - accuracy: 0.6284 - val_loss: 0.7074 - val_accuracy: 0.6811\n",
      "Epoch 20/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8080 - accuracy: 0.6187 - val_loss: 0.7566 - val_accuracy: 0.6654\n",
      "Epoch 21/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.6342 - val_loss: 0.7217 - val_accuracy: 0.6850\n",
      "Epoch 22/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7302 - accuracy: 0.6459 - val_loss: 0.7273 - val_accuracy: 0.6890\n",
      "Epoch 23/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7326 - accuracy: 0.6089 - val_loss: 0.7016 - val_accuracy: 0.7047\n",
      "Epoch 24/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.8228 - accuracy: 0.6304 - val_loss: 0.7246 - val_accuracy: 0.6850\n",
      "Epoch 25/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7037 - accuracy: 0.6323 - val_loss: 0.6565 - val_accuracy: 0.6929\n",
      "Epoch 26/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7018 - accuracy: 0.6323 - val_loss: 0.6539 - val_accuracy: 0.7087\n",
      "Epoch 27/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.6420 - val_loss: 0.6396 - val_accuracy: 0.6890\n",
      "Epoch 28/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.6420 - val_loss: 0.6569 - val_accuracy: 0.6890\n",
      "Epoch 29/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7182 - accuracy: 0.6381 - val_loss: 0.7965 - val_accuracy: 0.6024\n",
      "Epoch 30/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.6401 - val_loss: 0.6411 - val_accuracy: 0.7205\n",
      "Epoch 31/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7216 - accuracy: 0.6381 - val_loss: 0.7526 - val_accuracy: 0.6378\n",
      "Epoch 32/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7793 - accuracy: 0.6206 - val_loss: 0.7562 - val_accuracy: 0.6339\n",
      "Epoch 33/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.6673 - val_loss: 0.7151 - val_accuracy: 0.6732\n",
      "Epoch 34/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.6440 - val_loss: 0.7363 - val_accuracy: 0.6535\n",
      "Epoch 35/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6576 - val_loss: 0.6944 - val_accuracy: 0.6929\n",
      "Epoch 36/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7281 - accuracy: 0.6420 - val_loss: 1.0294 - val_accuracy: 0.6654\n",
      "Epoch 37/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7313 - accuracy: 0.6459 - val_loss: 0.7313 - val_accuracy: 0.6457\n",
      "Epoch 38/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.6654 - val_loss: 0.6095 - val_accuracy: 0.7126\n",
      "Epoch 39/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7022 - accuracy: 0.6226 - val_loss: 0.7537 - val_accuracy: 0.6614\n",
      "Epoch 40/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7715 - accuracy: 0.6206 - val_loss: 0.7218 - val_accuracy: 0.6693\n",
      "Epoch 41/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.6342 - val_loss: 0.6173 - val_accuracy: 0.7165\n",
      "Epoch 42/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7277 - accuracy: 0.6265 - val_loss: 0.6888 - val_accuracy: 0.6693\n",
      "Epoch 43/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.6770 - val_loss: 0.5908 - val_accuracy: 0.7283\n",
      "Epoch 44/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.6362 - val_loss: 0.5925 - val_accuracy: 0.7087\n",
      "Epoch 45/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.6459 - val_loss: 0.5807 - val_accuracy: 0.7244\n",
      "Epoch 46/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.6479 - val_loss: 0.7750 - val_accuracy: 0.6654\n",
      "Epoch 47/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7648 - accuracy: 0.6401 - val_loss: 0.9388 - val_accuracy: 0.6654\n",
      "Epoch 48/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.6595 - val_loss: 0.6012 - val_accuracy: 0.7087\n",
      "Epoch 49/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.6926 - val_loss: 0.6981 - val_accuracy: 0.6614\n",
      "Epoch 50/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.6595 - val_loss: 0.5832 - val_accuracy: 0.7480\n",
      "Epoch 51/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.6673 - val_loss: 0.6723 - val_accuracy: 0.6575\n",
      "Epoch 52/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.6673 - val_loss: 0.6054 - val_accuracy: 0.6890\n",
      "Epoch 53/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6051 - accuracy: 0.6809 - val_loss: 0.5715 - val_accuracy: 0.7126\n",
      "Epoch 54/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.6323 - val_loss: 0.5931 - val_accuracy: 0.7559\n",
      "Epoch 55/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.6887 - val_loss: 0.5753 - val_accuracy: 0.7402\n",
      "Epoch 56/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7032 - accuracy: 0.6362 - val_loss: 0.6003 - val_accuracy: 0.7362\n",
      "Epoch 57/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7086 - accuracy: 0.6304 - val_loss: 0.9853 - val_accuracy: 0.6693\n",
      "Epoch 58/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0031 - accuracy: 0.5973 - val_loss: 0.5701 - val_accuracy: 0.7205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.6809 - val_loss: 0.6166 - val_accuracy: 0.6929\n",
      "Epoch 60/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.6829 - val_loss: 0.7055 - val_accuracy: 0.6575\n",
      "Epoch 61/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.6984 - val_loss: 0.5704 - val_accuracy: 0.7402\n",
      "Epoch 62/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.6673 - val_loss: 0.5869 - val_accuracy: 0.6929\n",
      "Epoch 63/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6848 - val_loss: 0.5846 - val_accuracy: 0.6811\n",
      "Epoch 64/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6829 - val_loss: 0.6638 - val_accuracy: 0.6890\n",
      "Epoch 65/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7028 - accuracy: 0.6556 - val_loss: 0.7427 - val_accuracy: 0.6299\n",
      "Epoch 66/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.6790 - val_loss: 0.6251 - val_accuracy: 0.7087\n",
      "Epoch 67/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.6829 - val_loss: 0.6457 - val_accuracy: 0.6693\n",
      "Epoch 68/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.6926 - val_loss: 0.6350 - val_accuracy: 0.6654\n",
      "Epoch 69/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.6381 - val_loss: 0.7148 - val_accuracy: 0.6535\n",
      "Epoch 70/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.6887 - val_loss: 0.6237 - val_accuracy: 0.7126\n",
      "Epoch 71/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.6770 - val_loss: 0.5792 - val_accuracy: 0.7756\n",
      "Epoch 72/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6809 - val_loss: 0.6080 - val_accuracy: 0.7165\n",
      "Epoch 73/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.6615 - val_loss: 0.5749 - val_accuracy: 0.7441\n",
      "Epoch 74/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.6556 - val_loss: 0.5906 - val_accuracy: 0.7087\n",
      "Epoch 75/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.6984 - val_loss: 0.6459 - val_accuracy: 0.6969\n",
      "Epoch 76/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.6634 - val_loss: 0.6578 - val_accuracy: 0.6890\n",
      "Epoch 77/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6809 - val_loss: 0.5988 - val_accuracy: 0.7323\n",
      "Epoch 78/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6615 - val_loss: 0.7394 - val_accuracy: 0.6693\n",
      "Epoch 79/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6673 - val_loss: 0.6340 - val_accuracy: 0.6929\n",
      "Epoch 80/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.6751 - val_loss: 0.5762 - val_accuracy: 0.7323\n",
      "Epoch 81/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7082 - val_loss: 0.5967 - val_accuracy: 0.7008\n",
      "Epoch 82/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.6790 - val_loss: 0.6923 - val_accuracy: 0.6772\n",
      "Epoch 83/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.6751 - val_loss: 0.5638 - val_accuracy: 0.7244\n",
      "Epoch 84/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6751 - val_loss: 0.8006 - val_accuracy: 0.6693\n",
      "Epoch 85/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.9094 - accuracy: 0.6401 - val_loss: 0.5547 - val_accuracy: 0.6929\n",
      "Epoch 86/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.6751 - val_loss: 0.5721 - val_accuracy: 0.7480\n",
      "Epoch 87/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.6829 - val_loss: 0.5460 - val_accuracy: 0.7559\n",
      "Epoch 88/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6282 - accuracy: 0.6673 - val_loss: 0.5361 - val_accuracy: 0.7362\n",
      "Epoch 89/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5986 - accuracy: 0.6868 - val_loss: 0.7240 - val_accuracy: 0.6693\n",
      "Epoch 90/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6418 - accuracy: 0.6479 - val_loss: 0.5717 - val_accuracy: 0.7008\n",
      "Epoch 91/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6722 - accuracy: 0.6673 - val_loss: 0.5600 - val_accuracy: 0.7283\n",
      "Epoch 92/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7712 - accuracy: 0.6693 - val_loss: 0.5522 - val_accuracy: 0.7087\n",
      "Epoch 93/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.6868 - val_loss: 0.5366 - val_accuracy: 0.7402\n",
      "Epoch 94/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7179 - val_loss: 0.7020 - val_accuracy: 0.6772\n",
      "Epoch 95/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6868 - val_loss: 0.5407 - val_accuracy: 0.7717\n",
      "Epoch 96/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.7023 - val_loss: 0.5909 - val_accuracy: 0.6890\n",
      "Epoch 97/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.6770 - val_loss: 0.5371 - val_accuracy: 0.7717\n",
      "Epoch 98/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.6732 - val_loss: 0.5590 - val_accuracy: 0.7638\n",
      "Epoch 99/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.6907 - val_loss: 0.6316 - val_accuracy: 0.6811\n",
      "Epoch 100/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7102 - accuracy: 0.6323 - val_loss: 0.7018 - val_accuracy: 0.6772\n",
      "Epoch 101/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.7062 - val_loss: 0.6022 - val_accuracy: 0.6929\n",
      "Epoch 102/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.7121 - val_loss: 0.5748 - val_accuracy: 0.7205\n",
      "Epoch 103/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.7140 - val_loss: 0.5402 - val_accuracy: 0.7717\n",
      "Epoch 104/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7257 - val_loss: 0.6120 - val_accuracy: 0.7205\n",
      "Epoch 105/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.7043 - val_loss: 0.6762 - val_accuracy: 0.6457\n",
      "Epoch 106/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7214 - accuracy: 0.6459 - val_loss: 0.5330 - val_accuracy: 0.7205\n",
      "Epoch 107/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.7082 - val_loss: 0.5357 - val_accuracy: 0.7638\n",
      "Epoch 108/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7064 - accuracy: 0.6556 - val_loss: 0.8535 - val_accuracy: 0.6732\n",
      "Epoch 109/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.6829 - val_loss: 0.5323 - val_accuracy: 0.7598\n",
      "Epoch 110/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.6809 - val_loss: 0.6244 - val_accuracy: 0.6811\n",
      "Epoch 111/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6829 - val_loss: 0.5299 - val_accuracy: 0.7756\n",
      "Epoch 112/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7023 - val_loss: 0.5705 - val_accuracy: 0.6969\n",
      "Epoch 113/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.6984 - val_loss: 0.5347 - val_accuracy: 0.7756\n",
      "Epoch 114/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7296 - val_loss: 0.5323 - val_accuracy: 0.7874\n",
      "Epoch 115/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.7023 - val_loss: 0.5959 - val_accuracy: 0.7362\n",
      "Epoch 116/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.7276 - val_loss: 0.5577 - val_accuracy: 0.7283\n",
      "Epoch 117/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7140 - val_loss: 0.5324 - val_accuracy: 0.7835\n",
      "Epoch 118/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7237 - val_loss: 0.5252 - val_accuracy: 0.7913\n",
      "Epoch 119/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.6965 - val_loss: 0.5543 - val_accuracy: 0.7480\n",
      "Epoch 120/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7101 - val_loss: 0.5774 - val_accuracy: 0.7008\n",
      "Epoch 121/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.6809 - val_loss: 0.5279 - val_accuracy: 0.7283\n",
      "Epoch 122/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.7257 - val_loss: 0.5484 - val_accuracy: 0.7441\n",
      "Epoch 123/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7218 - val_loss: 0.5293 - val_accuracy: 0.7756\n",
      "Epoch 124/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.7121 - val_loss: 0.5973 - val_accuracy: 0.7402\n",
      "Epoch 125/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6770 - val_loss: 0.5350 - val_accuracy: 0.7283\n",
      "Epoch 126/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.6984 - val_loss: 0.5447 - val_accuracy: 0.7717\n",
      "Epoch 127/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7023 - val_loss: 0.5958 - val_accuracy: 0.6890\n",
      "Epoch 128/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.6907 - val_loss: 0.5441 - val_accuracy: 0.7874\n",
      "Epoch 129/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.7296 - val_loss: 0.5706 - val_accuracy: 0.7520\n",
      "Epoch 130/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7140 - val_loss: 0.5479 - val_accuracy: 0.7323\n",
      "Epoch 131/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.6751 - val_loss: 0.5336 - val_accuracy: 0.7362\n",
      "Epoch 132/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.7101 - val_loss: 0.5215 - val_accuracy: 0.7638\n",
      "Epoch 133/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7160 - val_loss: 0.6002 - val_accuracy: 0.6969\n",
      "Epoch 134/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.6946 - val_loss: 0.6844 - val_accuracy: 0.6693\n",
      "Epoch 135/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.6946 - val_loss: 0.5433 - val_accuracy: 0.7598\n",
      "Epoch 136/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7374 - val_loss: 0.5535 - val_accuracy: 0.7795\n",
      "Epoch 137/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7335 - val_loss: 0.5328 - val_accuracy: 0.7244\n",
      "Epoch 138/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.6595 - val_loss: 0.5235 - val_accuracy: 0.7480\n",
      "Epoch 139/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7393 - val_loss: 0.5160 - val_accuracy: 0.7677\n",
      "Epoch 140/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.7004 - val_loss: 0.5659 - val_accuracy: 0.7205\n",
      "Epoch 141/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7179 - val_loss: 0.5152 - val_accuracy: 0.7953\n",
      "Epoch 142/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6655 - accuracy: 0.6829 - val_loss: 0.5140 - val_accuracy: 0.7874\n",
      "Epoch 143/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6997 - accuracy: 0.6576 - val_loss: 0.5358 - val_accuracy: 0.7205\n",
      "Epoch 144/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7023 - val_loss: 0.5943 - val_accuracy: 0.7402\n",
      "Epoch 145/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.7160 - val_loss: 0.5183 - val_accuracy: 0.7520\n",
      "Epoch 146/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7335 - val_loss: 0.5748 - val_accuracy: 0.7402\n",
      "Epoch 147/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.7237 - val_loss: 0.5107 - val_accuracy: 0.7874\n",
      "Epoch 148/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.7198 - val_loss: 0.5277 - val_accuracy: 0.7992\n",
      "Epoch 149/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5263 - accuracy: 0.7510 - val_loss: 0.5141 - val_accuracy: 0.7756\n",
      "Epoch 150/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5702 - accuracy: 0.7315 - val_loss: 0.5338 - val_accuracy: 0.7953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a1354a7f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP with manual validation set\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# load pima indians dataset\n",
    "dataset = np.loadtxt('Datasets/pima-indians-diabetes.csv', delimiter =',')\n",
    "# split into input (X) and output (Y) variables\n",
    "x = dataset[:, 0:8]\n",
    "y = dataset[:, 8]\n",
    "# split into 67% for train and 33% for test\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x,y,test_size = 0.33)\n",
    "model = Sequential()\n",
    "model.add(Dense( 12, input_dim = 8, activation = 'relu'))\n",
    "model.add(Dense( 8, activation = 'relu'))\n",
    "model.add(Dense( 1, activation = 'sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(x,y, validation_split = 0.33, epochs = 150, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\" size=6>3. Validación cruzada</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada a menudo no se usa para evaluar modelos de aprendizaje profundo debido al mayor gasto computacional, demasiadas iteraciones para modelos muy pesados.\n",
    "\n",
    "En el siguiente ejemplo, usamos el práctico clase `StratifiedKFold` de scikit-learn para dividir el conjunto de datos de entrenamiento en 10-folds. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 67.53%\n",
      "accuracy 75.32%\n",
      "accuracy 72.73%\n",
      "accuracy 66.23%\n",
      "accuracy 67.53%\n",
      "accuracy 70.13%\n",
      "accuracy 79.22%\n",
      "accuracy 68.83%\n",
      "accuracy 67.11%\n",
      "accuracy 69.74%\n",
      "0.69%(+/- 3.94%)\n"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset with 10-fold cross validation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# load pima indians dataset\n",
    "dataset = np.loadtxt('Datasets/pima-indians-diabetes.csv', delimiter =',')\n",
    "# split into input (X) and output (Y) variables\n",
    "x = dataset[:, 0:8]\n",
    "y = dataset[:, 8]\n",
    "# define 10-fold cross validation test harness\n",
    "cvscores = []\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle = True, random_state= 7)\n",
    "for train, test in kfold.split(x,y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense( 12, input_dim = 8, activation = 'relu'))\n",
    "    model.add(Dense( 8, activation = 'relu'))\n",
    "    model.add(Dense( 1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    model.fit(x[train], y[train],epochs = 150, batch_size =10,verbose = 0)\n",
    "    \n",
    "    scores = model.evaluate(x[test], y[test], verbose =0)\n",
    "    \n",
    "    print('%s %.2f%%' % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1]*100)\n",
    "print('%.2f%%(+/- %.2f%%)' % (np.mean(scores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Se ha tenido que volver a crear el modelo en cada bucle para luego ajustarlo y evaluarlo con los datos del fold. En la próxima lección veremos cómo podemos usar los modelos de Keras de forma nativa con Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
